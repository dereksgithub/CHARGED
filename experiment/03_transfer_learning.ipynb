{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Transfer Learning Across Cities\n",
    "\n",
    "This notebook demonstrates transfer learning for EV charging prediction:\n",
    "1. Pre-train on data-rich cities (Shenzhen, Amsterdam, Los Angeles)\n",
    "2. Fine-tune on data-sparse cities (Melbourne, Johannesburg, São Paulo)\n",
    "3. Compare with training from scratch\n",
    "\n",
    "**Goal**: Demonstrate 15-30% MAE improvement through transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from api.dataset.common import EVDataset\n",
    "from api.dataset.distributed import DistributedEVDataset\n",
    "from api.model.foundation import load_foundation_model\n",
    "from api.utils import calculate_regression_metrics\n",
    "from experiment.utils.experiment_tracking import ExperimentTracker\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Data-rich cities for pre-training\n",
    "    'pretrain_cities': ['SZH', 'AMS', 'LOA'],\n",
    "    \n",
    "    # Data-sparse cities for transfer learning\n",
    "    'target_cities': ['MEL', 'JHB', 'SPO'],\n",
    "    \n",
    "    # Model configuration\n",
    "    'model_name': 'moment',\n",
    "    'model_size': 'small',\n",
    "    'feature': 'volume',\n",
    "    'auxiliary': 'all',\n",
    "    \n",
    "    # Pre-training\n",
    "    'pretrain_epochs': 50,\n",
    "    'pretrain_batch_size': 64,\n",
    "    'pretrain_lr': 1e-4,\n",
    "    \n",
    "    # Fine-tuning\n",
    "    'finetune_epochs': 20,\n",
    "    'finetune_batch_size': 32,\n",
    "    'finetune_lr': 1e-5,\n",
    "    'freeze_encoder': True,\n",
    "    'unfreeze_layers': 2,\n",
    "    \n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "\n",
    "print(\"Transfer Learning Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pre-train on Data-Rich Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: MULTI-CITY PRE-TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPre-training on: {', '.join(CONFIG['pretrain_cities'])}\")\n",
    "\n",
    "# Load datasets from multiple cities\n",
    "print(\"\\nLoading datasets...\")\n",
    "city_datasets = {}\n",
    "\n",
    "for city in CONFIG['pretrain_cities']:\n",
    "    data_path = f'../data/{city}_remove_zero/'\n",
    "    print(f\"  Loading {city}...\")\n",
    "    \n",
    "    dataset = EVDataset(\n",
    "        feature=CONFIG['feature'],\n",
    "        auxiliary=CONFIG['auxiliary'],\n",
    "        data_path=data_path,\n",
    "        pred_type='site'\n",
    "    )\n",
    "    \n",
    "    city_datasets[city] = dataset\n",
    "    print(f\"    {city}: {dataset.feat.shape[1]} sites, {dataset.feat.shape[0]} timesteps\")\n",
    "\n",
    "total_sites = sum(ds.feat.shape[1] for ds in city_datasets.values())\n",
    "print(f\"\\n✓ Total sites for pre-training: {total_sites}\")\n",
    "\n",
    "# TODO: Implement multi-city data combination and training\n",
    "print(\"\\n⚠️  Multi-city training implementation needed\")\n",
    "print(\"You can use api/dataset/distributed.py as reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fine-tune on Target Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: FINE-TUNING ON TARGET CITIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "transfer_results = []\n",
    "\n",
    "for target_city in CONFIG['target_cities']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Target City: {target_city}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load target city data\n",
    "    data_path = f'../data/{target_city}_remove_zero/'\n",
    "    print(f\"Loading {target_city} dataset...\")\n",
    "    \n",
    "    target_dataset = EVDataset(\n",
    "        feature=CONFIG['feature'],\n",
    "        auxiliary=CONFIG['auxiliary'],\n",
    "        data_path=data_path,\n",
    "        pred_type='site'\n",
    "    )\n",
    "    \n",
    "    target_dataset.split_cross_validation(\n",
    "        fold=1,\n",
    "        total_fold=6,\n",
    "        train_ratio=0.8,\n",
    "        valid_ratio=0.1\n",
    "    )\n",
    "    \n",
    "    print(f\"  Sites: {target_dataset.feat.shape[1]}\")\n",
    "    print(f\"  Training samples: {len(target_dataset.train_feat)}\")\n",
    "    \n",
    "    # TODO: Load pre-trained model and fine-tune\n",
    "    print(\"\\n  ⚠️  Fine-tuning implementation needed\")\n",
    "    \n",
    "    # Placeholder result\n",
    "    transfer_results.append({\n",
    "        'city': target_city,\n",
    "        'sites': target_dataset.feat.shape[1],\n",
    "        'status': 'template'\n",
    "    })\n",
    "\n",
    "print(\"\\n✓ Template for all target cities created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Baseline - Train from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: TRAIN FROM SCRATCH (BASELINE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "scratch_results = []\n",
    "\n",
    "for target_city in CONFIG['target_cities']:\n",
    "    print(f\"\\nTraining from scratch on {target_city}...\")\n",
    "    \n",
    "    # TODO: Train model from random initialization\n",
    "    print(\"  ⚠️  From-scratch training implementation needed\")\n",
    "    \n",
    "    scratch_results.append({\n",
    "        'city': target_city,\n",
    "        'status': 'template'\n",
    "    })\n",
    "\n",
    "print(\"\\n✓ Baseline templates created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Transfer vs From-Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSFER LEARNING COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nWhen implemented, this section will show:\")\n",
    "print(\"  1. MAE comparison: Transfer vs From-Scratch\")\n",
    "print(\"  2. Convergence speed: Epochs to reach target performance\")\n",
    "print(\"  3. Data efficiency: Performance with limited training data\")\n",
    "print(\"  4. Per-city breakdown\")\n",
    "\n",
    "print(\"\\nExpected result: 15-30% MAE improvement with transfer learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Roadmap\n",
    "\n",
    "To complete this notebook:\n",
    "\n",
    "### 1. Multi-City Data Handling\n",
    "Reference: `api/dataset/distributed.py`\n",
    "- Combine datasets from multiple cities\n",
    "- Handle city-specific normalization\n",
    "- Create unified data loaders\n",
    "\n",
    "### 2. Pre-Training Loop\n",
    "- Load foundation model\n",
    "- Train on combined SZH+AMS+LOA data\n",
    "- Save checkpoint: `results/transfer_learning/pretrained/multi_city.pth`\n",
    "\n",
    "### 3. Fine-Tuning Loop\n",
    "- Load pre-trained checkpoint\n",
    "- Freeze encoder, unfreeze last N layers\n",
    "- Train on target city (MEL/JHB/SPO)\n",
    "- Evaluate and save results\n",
    "\n",
    "### 4. Baseline Comparison\n",
    "- Train same architecture from random initialization\n",
    "- Use same training data as fine-tuning\n",
    "- Compare metrics\n",
    "\n",
    "### Alternative Approach\n",
    "You can also leverage the existing federated learning infrastructure:\n",
    "- `example/knowledge_transfer.py` shows multi-city training\n",
    "- `api/federated/` has client-server architecture\n",
    "- Adapt for transfer learning instead of federated averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save template status\n",
    "results_df = pd.DataFrame({\n",
    "    'pretrain_cities': [', '.join(CONFIG['pretrain_cities'])] * len(CONFIG['target_cities']),\n",
    "    'target_city': CONFIG['target_cities'],\n",
    "    'status': ['template'] * len(CONFIG['target_cities'])\n",
    "})\n",
    "\n",
    "results_df.to_csv('../results/transfer_learning/template_status.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 3 TEMPLATE COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTransfer learning framework structure created.\")\n",
    "print(\"See implementation roadmap above for next steps.\")\n",
    "print(\"\\nRecommended: Start with single-city fine-tuning first,\")\n",
    "print(\"then scale to multi-city pre-training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
